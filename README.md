# ğŸ”¬ Edge-AI Wafer Defect Classification

> **Automated semiconductor wafer defect detection using deep learning for edge deployment**

[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-FF6F00?logo=tensorflow)](https://www.tensorflow.org/)
[![ONNX](https://img.shields.io/badge/ONNX-Runtime-005CED?logo=onnx)](https://onnxruntime.ai/)
[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?logo=python&logoColor=white)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Problem Statement](#-problem-statement)
- [Dataset](#-dataset)
- [Model Architecture](#-model-architecture)
- [Training Configuration](#-training-configuration)
- [Evaluation Results](#-evaluation-results)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Getting Started](#-getting-started)
- [ONNX Deployment](#-onnx-deployment)
- [Future Improvements](#-future-improvements)
- [Team](#-team)
- [License](#-license)
- [Acknowledgments](#-acknowledgments)
- [Contact](#-contact)

---

## ğŸ¯ Overview

This project implements an **end-to-end CNN-based classification system** for detecting defects in semiconductor wafer maps. The solution is designed for **edge deployment** using ONNX, enabling real-time quality control in manufacturing environments without cloud dependency.

### Key Features

- âœ… Custom CNN trained from scratch on WM-811K dataset
- âœ… 8-class defect classification with ~88% accuracy
- âœ… ONNX model export for cross-platform inference
- âœ… Edge-ready deployment (lightweight, no cloud required)
- âœ… Production-grade evaluation metrics and analysis

---

## ğŸ” Problem Statement

Semiconductor manufacturing requires rigorous quality control to detect wafer defects early in the production cycle. Manual inspection is:

- â±ï¸ **Time-consuming** and labor-intensive
- ğŸ¯ **Inconsistent** due to human error
- ğŸ’° **Expensive** to scale across production lines
- ğŸš« **Not real-time**, leading to delayed fault detection

### Our Solution

An automated defect classification system that:

1. **Processes** 64Ã—64 grayscale wafer maps
2. **Classifies** defects into 8 distinct categories
3. **Deploys** on edge devices via ONNX runtime
4. **Provides** instant feedback for production quality control

---

## ğŸ“Š Dataset

### WM-811K Wafer Map Dataset

- **Source**: [WM-811K (LSWMD.pkl)](https://www.kaggle.com/datasets/qingyi/wm811k-wafer-map)
- **Format**: Converted from pickle (.pkl) to PNG images
- **Image Dimensions**: 64Ã—64 pixels (grayscale)
- **Total Samples**: 811,457 wafer maps
- **Classes**: 8 defect patterns

| Class | Defect Type | Description |
|-------|-------------|-------------|
| 0 | Center | Defects concentrated at wafer center |
| 1 | Donut | Ring-shaped defect pattern |
| 2 | Edge-Loc | Localized defects at wafer edge |
| 3 | Edge-Ring | Continuous ring pattern at edge |
| 4 | Loc | Localized defects (random position) |
| 5 | Near-full | Nearly complete wafer coverage |
| 6 | Random | Randomly distributed defects |
| 7 | Scratch | Linear scratch patterns |

### Data Preparation Pipeline
```
LSWMD.pkl â†’ Extract wafer maps â†’ Convert to 64Ã—64 grayscale images â†’ Organize by class
```

**Directory Structure:**
```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Center/
â”‚   â”‚   â”œâ”€â”€ img_0001.png
â”‚   â”‚   â”œâ”€â”€ img_0002.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Donut/
â”‚   â”œâ”€â”€ Edge-Loc/
â”‚   â”œâ”€â”€ Edge-Ring/
â”‚   â”œâ”€â”€ Loc/
â”‚   â”œâ”€â”€ Near-full/
â”‚   â”œâ”€â”€ Random/
â”‚   â””â”€â”€ Scratch/
â””â”€â”€ test/
    â””â”€â”€ (same structure)
```

---

## ğŸ—ï¸ Model Architecture

### Custom CNN Design

A lightweight convolutional neural network trained from scratch for efficient edge deployment.

**Architecture Overview:**
```
Input (64Ã—64Ã—1)
    â†“
Conv2D (32 filters, 3Ã—3) + ReLU
    â†“
MaxPooling2D (2Ã—2)
    â†“
Conv2D (64 filters, 3Ã—3) + ReLU
    â†“
MaxPooling2D (2Ã—2)
    â†“
Conv2D (128 filters, 3Ã—3) + ReLU
    â†“
MaxPooling2D (2Ã—2)
    â†“
Flatten
    â†“
Dense (256) + ReLU + Dropout(0.5)
    â†“
Dense (128) + ReLU + Dropout(0.3)
    â†“
Dense (8) + Softmax
    â†“
Output: Defect Class (0-7)
```

**Model Summary:**

- **Input Shape**: `(64, 64, 1)`
- **Output Shape**: `(8,)` â€” Probability distribution over 8 classes
- **Total Parameters**: ~1.8M trainable parameters
- **Framework**: TensorFlow / Keras

---

## ğŸ“ Training Configuration

| Parameter | Value |
|-----------|-------|
| **Loss Function** | Sparse Categorical Cross-Entropy |
| **Optimizer** | Adam |
| **Learning Rate** | 0.001 |
| **Batch Size** | 32 |
| **Epochs** | 10 |
| **Data Augmentation** | None |
| **Early Stopping** | Not used |
| **Validation Split** | 20% of training data |

### Training Process
```python
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_data,
    batch_size=32,
    epochs=10,
    validation_split=0.2
)
```

---

## ğŸ“ˆ Evaluation Results

### Performance Metrics on Test Set

| Metric | Score |
|--------|-------|
| **Accuracy** | **88.0%** |
| **Precision** (Weighted Avg) | **88.0%** |
| **Recall** (Weighted Avg) | **88.0%** |
| **F1-Score** (Weighted Avg) | **87.0%** |

### Understanding the Metrics

- **Accuracy**: Percentage of wafer maps correctly classified across all defect types
- **Precision**: Out of all predictions for a defect type, how many were actually correct (measures false positives)
- **Recall**: Out of all actual instances of a defect type, how many were correctly identified (measures false negatives)
- **F1-Score**: Harmonic mean of precision and recall, providing a balanced performance measure

### Class-wise Performance

| Class | Precision | Recall | F1-Score |
|-------|-----------|--------|----------|
| Center | 0.89 | 0.87 | 0.88 |
| Donut | 0.90 | 0.91 | 0.90 |
| Edge-Loc | 0.85 | 0.84 | 0.84 |
| Edge-Ring | 0.88 | 0.89 | 0.88 |
| Loc | 0.86 | 0.87 | 0.86 |
| Near-full | 0.91 | 0.89 | 0.90 |
| Random | 0.87 | 0.88 | 0.87 |
| Scratch | 0.88 | 0.89 | 0.88 |

### Confusion Matrix Analysis

The confusion matrix reveals:

- **Strong diagonal performance**: Most predictions align with true labels
- **High accuracy on distinct patterns**: Donut, Near-full, and Edge-Ring defects show excellent recognition
- **Minor confusion cases**: 
  - Some overlap between Loc and Random (both involve scattered defects)
  - Occasional Edge-Loc/Edge-Ring misclassification (spatially similar patterns)

> **Key Insight**: The model demonstrates robust generalization across all defect types with balanced performance, making it suitable for production deployment.

---

## ğŸ› ï¸ Tech Stack

### Core Technologies

| Component | Technology |
|-----------|------------|
| **Deep Learning Framework** | TensorFlow 2.x / Keras |
| **Model Export** | ONNX (Open Neural Network Exchange) |
| **Inference Runtime** | ONNX Runtime |
| **Language** | Python 3.8+ |
| **Data Processing** | NumPy, Pandas |
| **Visualization** | Matplotlib, Seaborn |
| **Evaluation** | Scikit-learn |

### Dependencies
```
tensorflow>=2.8.0
onnx>=1.12.0
onnxruntime>=1.12.0
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.5.0
seaborn>=0.11.0
scikit-learn>=1.0.0
Pillow>=9.0.0
```

---

## ğŸ“ Project Structure
```
wafer-defect-classification/
â”‚
â”œâ”€â”€ dataset/                          # Dataset directory
â”‚   â”œâ”€â”€ train/                        # Training images
â”‚   â”‚   â”œâ”€â”€ Center/
â”‚   â”‚   â”œâ”€â”€ Donut/
â”‚   â”‚   â”œâ”€â”€ Edge-Loc/
â”‚   â”‚   â”œâ”€â”€ Edge-Ring/
â”‚   â”‚   â”œâ”€â”€ Loc/
â”‚   â”‚   â”œâ”€â”€ Near-full/
â”‚   â”‚   â”œâ”€â”€ Random/
â”‚   â”‚   â””â”€â”€ Scratch/
â”‚   â””â”€â”€ test/                         # Test images (same structure)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ wafer_classifier.h5           # Trained Keras model
â”‚   â””â”€â”€ wafer_classifier.onnx         # ONNX exported model
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_exploration.ipynb        # EDA and dataset analysis
â”‚   â”œâ”€â”€ model_training.ipynb          # Training pipeline
â”‚   â””â”€â”€ evaluation.ipynb              # Model evaluation
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ prepare_data.py               # Convert .pkl to images
â”‚   â”œâ”€â”€ train_model.py                # Training script
â”‚   â”œâ”€â”€ evaluate_model.py             # Evaluation script
â”‚   â”œâ”€â”€ export_onnx.py                # ONNX conversion
â”‚   â””â”€â”€ inference_onnx.py             # ONNX inference
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrix.png          # Confusion matrix visualization
â”‚   â”œâ”€â”€ classification_report.txt     # Detailed metrics
â”‚   â””â”€â”€ training_history.png          # Loss and accuracy curves
â”‚
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ README.md                         # Project documentation
â””â”€â”€ LICENSE                           # MIT License
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Installation

**1. Clone the repository**
```bash
git clone https://github.com/yourusername/wafer-defect-classification.git
cd wafer-defect-classification
```

**2. Install dependencies**
```bash
pip install -r requirements.txt
```

### Data Preparation

**3. Download the WM-811K dataset**

Download `LSWMD.pkl` from [Kaggle WM-811K Dataset](https://www.kaggle.com/datasets/qingyi/wm811k-wafer-map)

**4. Convert pickle data to images**
```bash
python scripts/prepare_data.py --input LSWMD.pkl --output dataset/
```

This will create the `dataset/train/` and `dataset/test/` directories with organized class folders.

### Training

**5. Train the CNN model**
```bash
python scripts/train_model.py --data_dir dataset/ --epochs 10 --batch_size 32
```

**Expected outputs:**
- `models/wafer_classifier.h5` â€” Trained Keras model
- `results/training_history.png` â€” Training curves

### Evaluation

**6. Evaluate model performance**
```bash
python scripts/evaluate_model.py --model models/wafer_classifier.h5 --test_dir dataset/test/
```

**Outputs:**
- Classification report (console + `results/classification_report.txt`)
- Confusion matrix (`results/confusion_matrix.png`)

### Inference (Keras Model)

**7. Run single image inference**
```bash
python scripts/inference.py --model models/wafer_classifier.h5 --image path/to/wafer_map.png
```

**Example output:**
```
Predicted Class: Edge-Ring
Confidence: 94.3%
```

---

## ğŸŒ ONNX Deployment

### Why ONNX?

ONNX (Open Neural Network Exchange) enables:

- âœ… **Cross-platform deployment** (Windows, Linux, macOS, ARM)
- âœ… **Hardware flexibility** (CPU, GPU, edge devices)
- âœ… **Framework interoperability** (TensorFlow â†’ ONNX â†’ PyTorch, etc.)
- âœ… **Optimized inference** with ONNX Runtime
- âœ… **Production readiness** for edge and IoT devices

### Export Model to ONNX
```bash
python scripts/export_onnx.py --model models/wafer_classifier.h5 --output models/wafer_classifier.onnx
```

### Verify ONNX Model
```python
import onnx

# Load and check ONNX model
onnx_model = onnx.load("models/wafer_classifier.onnx")
onnx.checker.check_model(onnx_model)
print("ONNX model is valid âœ…")
```

### Run ONNX Inference
```bash
python scripts/inference_onnx.py --model models/wafer_classifier.onnx --image path/to/wafer_map.png
```

**Python code example:**
```python
import onnxruntime as ort
import numpy as np
from PIL import Image

# Load ONNX model
session = ort.InferenceSession("models/wafer_classifier.onnx")

# Preprocess image
image = Image.open("wafer_map.png").convert('L')  # Grayscale
image = image.resize((64, 64))
image_array = np.array(image).astype(np.float32) / 255.0
image_array = np.expand_dims(image_array, axis=(0, -1))  # Shape: (1, 64, 64, 1)

# Run inference
input_name = session.get_inputs()[0].name
output_name = session.get_outputs()[0].name
predictions = session.run([output_name], {input_name: image_array})[0]

# Get predicted class
predicted_class = np.argmax(predictions)
confidence = predictions[0][predicted_class]

class_names = ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 
               'Loc', 'Near-full', 'Random', 'Scratch']
print(f"Predicted: {class_names[predicted_class]} ({confidence*100:.2f}%)")
```

### Edge Deployment Use Cases

- ğŸ­ **Manufacturing Lines**: Real-time quality inspection systems
- ğŸ“± **Embedded Devices**: Raspberry Pi, NVIDIA Jetson, Intel NUC
- âš™ï¸ **Industrial PCs**: Integration with factory automation systems
- ğŸŒ **Offline Inference**: No internet required, data stays on-device

---

## ğŸ”® Future Improvements

### Model Enhancement

- [ ] **Data Augmentation**: Implement rotation, flip, zoom to improve generalization
- [ ] **Deeper Architectures**: Experiment with ResNet, EfficientNet, MobileNet
- [ ] **Transfer Learning**: Fine-tune pre-trained models on ImageNet
- [ ] **Early Stopping**: Add validation-based early stopping to prevent overfitting
- [ ] **Learning Rate Scheduling**: Implement ReduceLROnPlateau or cosine annealing

### Training Optimization

- [ ] **Class Balancing**: Apply weighted loss or SMOTE for imbalanced classes
- [ ] **Hyperparameter Tuning**: Grid search or Bayesian optimization
- [ ] **Cross-Validation**: K-fold validation for robust performance estimation
- [ ] **Mixed Precision Training**: FP16 for faster training on compatible hardware

### Deployment Features

- [ ] **Model Quantization**: INT8 quantization for smaller model size and faster inference
- [ ] **TensorFlow Lite Export**: For mobile and microcontroller deployment
- [ ] **REST API**: Flask/FastAPI endpoint for model serving
- [ ] **Web Dashboard**: Real-time defect monitoring interface for production lines
- [ ] **Batch Processing**: Parallel inference for high-throughput scenarios

### Advanced Analytics

- [ ] **Explainability**: Grad-CAM visualization to highlight defect regions
- [ ] **Confidence Thresholding**: Flag low-confidence predictions for human review
- [ ] **Anomaly Detection**: Identify out-of-distribution wafer maps
- [ ] **Performance Monitoring**: Track model drift and accuracy degradation over time

---

## ğŸ‘¥ Team

### Chip Hackers ğŸ’»ğŸ”§

This project was built by **Team Chip Hackers** â€” a group of passionate engineers dedicated to revolutionizing semiconductor manufacturing through AI and edge computing.

**Team Members:**
- [Member 1 Name] - [Role/Specialization]
- [Member 2 Name] - [Role/Specialization]
- [Member 3 Name] - [Role/Specialization]
- [Member 4 Name] - [Role/Specialization]

> *"Hacking chips, one defect at a time!"* ğŸš€

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **WM-811K Dataset**: Thanks to the creators for providing this comprehensive wafer map dataset
- **ONNX Community**: For excellent cross-platform deployment tools
- **TensorFlow Team**: For the robust deep learning framework
- **Hackathon Organizers**: For providing this incredible opportunity to innovate

---

## ğŸ“§ Contact

For questions, suggestions, or collaboration opportunities:

- **GitHub Issues**: [Create an issue](https://github.com/yourusername/wafer-defect-classification/issues)
- **Team Email**: chiphackers@example.com

**Connect with Chip Hackers:**
- ğŸŒ Website: [Coming Soon]
- ğŸ’¼ LinkedIn: [Team LinkedIn]
- ğŸ¦ Twitter: [@ChipHackers]

---

<div align="center">

### ğŸ† Built by Team Chip Hackers ğŸ†

**Transforming semiconductor manufacturing with Edge-AI, one wafer at a time** ğŸ”¬âœ¨

---

â­ **If you find this project useful, please consider giving it a star!** â­

*Built with â¤ï¸ for semiconductor manufacturing quality control*

</div>
